{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks in Matrix Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the previous lesson, we saw how an individual neuron as a linear regression, fed into a non-linear activation function.  Then we saw that a neural network is a collection of activation functions.  In this lesson, we'll see how to conceptualize this, not only in terms of diagrams, but also in terms of matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing our inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting component, is that here we think of our inputs as one long vector.  So we can imagine that we are considering a single observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $a_{11} a_{12} a_{13}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in applying the linear component, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[w_1, w_2, w_3]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[w_1, w_2, w_3] * [a_{11}, a_{21}, a_{31}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that would be if we only were training a single neuron, with a single linear component.  Really, we have multiple linear functions, one for each neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $[w_{11}, w_{12}, w_{13}] * [a_{1}, a_{2}, a_{3}] $\n",
    "* $[w_{21}, w_{22}, w_{23}] * [a_{1}, a_{2}, a_{3}] $\n",
    "* $[w_{31}, w_{32}, w_{33}]* [a_{1}, a_{2}, a_{3}] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reduces to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $z_1 = w_1*x_{1}  +  w_2*x_{2} + w_3*x_{3} $\n",
    "\n",
    "* $z_2 = w_{21}*x_{1}  +  w_{22}*x_{2} + w_{23}*x_{3} $\n",
    "\n",
    "* $z_3 = w_{31}*x_{1}  +  w_{32}*x_{2} + w_{33}*x_{3} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in other words, applying our different linear functions to the same inputs.  And then from there, we get a vector z, that represents the results of these different linear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./neural-networks-matrix-form.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = $[z_1, z_2, z_3]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply our activation function, elementwise, to $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a(z) = a(z_1), a(z_2), a(z_3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can think of this as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single layer: $\\sigma(Wa_0 + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* At 15:16 in the 3blue1brown neural network, has the Network code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
